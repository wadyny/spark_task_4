{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9030f6ad-f4fa-4d44-8679-b4db98905734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Импорт библиотек\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import max, avg, min\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "from pyspark.sql.functions import when\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b6f5b79-ccf6-46b4-99ba-1abe1bc1d4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Инициализация Spark-сессии - create local SparkSession\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"Data Salaries\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "160fb69e-f872-48aa-ae0f-f2efe329fff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read with inferSchema duration: 3.559 sec\n"
     ]
    }
   ],
   "source": [
    "# 3. read csv with inferschema\n",
    "file_path = \"/home/jovyan/work/ds_salaries.csv\"\n",
    "\n",
    "t0 = time.time()\n",
    "df_infer = (spark.read\n",
    "         .csv(\n",
    "             file_path,\n",
    "             header=True,         \n",
    "             inferSchema=True,    \n",
    "             sep=\",\"              \n",
    "         ))\n",
    "t1 = time.time()\n",
    "print(f\"Read with inferSchema duration: {t1 - t0:.3f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a22fef5-5204-4be3-849e-25143bb6c12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second read with inferSchema duration: 0.263 sec\n"
     ]
    }
   ],
   "source": [
    "# 4. показать повторное чтение - read csv one more time with the same code and you will see that it almostly don't take time,\n",
    "# because info already in SparkSession and it will not read nothing from this file\n",
    "\n",
    "t0 = time.time()\n",
    "df_infer2 = (spark.read\n",
    "             .option(\"header\", True)\n",
    "             .option(\"sep\", \",\")\n",
    "             .option(\"inferSchema\", True)\n",
    "             .csv(file_path))\n",
    "t1 = time.time()\n",
    "print(f\"Second read with inferSchema duration: {t1 - t0:.3f} sec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85907a4a-9a0c-47a4-be0b-5527da2d583f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- work_year: integer (nullable = true)\n",
      " |-- experience_level: string (nullable = true)\n",
      " |-- employment_type: string (nullable = true)\n",
      " |-- job_title: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- salary_currency: string (nullable = true)\n",
      " |-- salary_in_usd: integer (nullable = true)\n",
      " |-- employee_residence: string (nullable = true)\n",
      " |-- remote_ratio: integer (nullable = true)\n",
      " |-- company_location: string (nullable = true)\n",
      " |-- company_size: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. write schema of csv on screen\n",
    "df_infer.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b70e52a-e6cf-490f-b671-43bac9058e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. create schema of this csv - схему задали \n",
    "schema = StructType([\n",
    "    StructField(\"work_year\", IntegerType(), True),\n",
    "    StructField(\"experience_level\", StringType(), True),\n",
    "    StructField(\"employment_type\", StringType(), True),\n",
    "    StructField(\"job_title\", StringType(), True),\n",
    "    StructField(\"salary\", IntegerType(), True),\n",
    "    StructField(\"salary_currency\", StringType(), True),\n",
    "    StructField(\"salary_in_usd\", IntegerType(), True),\n",
    "    StructField(\"employee_residence\", StringType(), True),\n",
    "    StructField(\"remote_ratio\", IntegerType(), True),\n",
    "    StructField(\"company_location\", StringType(), True),\n",
    "    StructField(\"company_size\", StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17c7ea5a-a0fc-4f76-af8a-3b475d4b8140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema provided manually (df_schema):\n",
      "root\n",
      " |-- work_year: integer (nullable = true)\n",
      " |-- experience_level: string (nullable = true)\n",
      " |-- employment_type: string (nullable = true)\n",
      " |-- job_title: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- salary_currency: string (nullable = true)\n",
      " |-- salary_in_usd: integer (nullable = true)\n",
      " |-- employee_residence: string (nullable = true)\n",
      " |-- remote_ratio: integer (nullable = true)\n",
      " |-- company_location: string (nullable = true)\n",
      " |-- company_size: string (nullable = true)\n",
      "\n",
      "Counts: infer vs schema: 607 607\n",
      "First 5 rows from infer:\n",
      "+---+---------+----------------+---------------+--------------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|_c0|work_year|experience_level|employment_type|job_title                 |salary|salary_currency|salary_in_usd|employee_residence|remote_ratio|company_location|company_size|\n",
      "+---+---------+----------------+---------------+--------------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|0  |2020     |MI              |FT             |Data Scientist            |70000 |EUR            |79833        |DE                |0           |DE              |L           |\n",
      "|1  |2020     |SE              |FT             |Machine Learning Scientist|260000|USD            |260000       |JP                |0           |JP              |S           |\n",
      "|2  |2020     |SE              |FT             |Big Data Engineer         |85000 |GBP            |109024       |GB                |50          |GB              |M           |\n",
      "|3  |2020     |MI              |FT             |Product Data Analyst      |20000 |USD            |20000        |HN                |0           |HN              |S           |\n",
      "|4  |2020     |SE              |FT             |Machine Learning Engineer |150000|USD            |150000       |US                |50          |US              |L           |\n",
      "+---+---------+----------------+---------------+--------------------------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "First 5 rows from schema:\n",
      "+---------+----------------+---------------+---------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|work_year|experience_level|employment_type|job_title|salary|salary_currency|salary_in_usd|employee_residence|remote_ratio|company_location|company_size|\n",
      "+---------+----------------+---------------+---------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|0        |2020            |MI             |FT       |NULL  |70000          |NULL         |79833             |NULL        |0               |DE          |\n",
      "|1        |2020            |SE             |FT       |NULL  |260000         |NULL         |260000            |NULL        |0               |JP          |\n",
      "|2        |2020            |SE             |FT       |NULL  |85000          |NULL         |109024            |NULL        |50              |GB          |\n",
      "|3        |2020            |MI             |FT       |NULL  |20000          |NULL         |20000             |NULL        |0               |HN          |\n",
      "|4        |2020            |SE             |FT       |NULL  |150000         |NULL         |150000            |NULL        |50              |US          |\n",
      "+---------+----------------+---------------+---------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7.  restart kernel without cleaning output and after restarting you need to initialize SparkSession, after initialize start execute only cells from cell with schema= =StructType....\n",
    "# To restart kernel click Kernel, Restart.\n",
    "df_schema = (spark.read\n",
    "             .option(\"header\", True)\n",
    "             .option(\"sep\", \",\")\n",
    "             .schema(schema)\n",
    "             .csv(file_path))\n",
    "\n",
    "print(\"Schema provided manually (df_schema):\")\n",
    "df_schema.printSchema()\n",
    "\n",
    "# Сравниваем результаты - read ds_salaries with predefined schema and compare results from this cell and cell with inferSchema\n",
    "print(\"Counts: infer vs schema:\", df_infer.count(), df_schema.count())\n",
    "print(\"First 5 rows from infer:\")\n",
    "df_infer.show(5, truncate=False)\n",
    "print(\"First 5 rows from schema:\")\n",
    "df_schema.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18ecb264-e017-4bbf-822c-86bb4c6f3005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema (again) from df_infer:\n",
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- work_year: integer (nullable = true)\n",
      " |-- experience_level: string (nullable = true)\n",
      " |-- employment_type: string (nullable = true)\n",
      " |-- job_title: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- salary_currency: string (nullable = true)\n",
      " |-- salary_in_usd: integer (nullable = true)\n",
      " |-- employee_residence: string (nullable = true)\n",
      " |-- remote_ratio: integer (nullable = true)\n",
      " |-- company_location: string (nullable = true)\n",
      " |-- company_size: string (nullable = true)\n",
      "\n",
      "Schema (again) from df_schema:\n",
      "root\n",
      " |-- work_year: integer (nullable = true)\n",
      " |-- experience_level: string (nullable = true)\n",
      " |-- employment_type: string (nullable = true)\n",
      " |-- job_title: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      " |-- salary_currency: string (nullable = true)\n",
      " |-- salary_in_usd: integer (nullable = true)\n",
      " |-- employee_residence: string (nullable = true)\n",
      " |-- remote_ratio: integer (nullable = true)\n",
      " |-- company_location: string (nullable = true)\n",
      " |-- company_size: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 8.  lazy/eager \n",
    "print(\"Schema (again) from df_infer:\")\n",
    "df_infer.printSchema()\n",
    "print(\"Schema (again) from df_schema:\")\n",
    "df_schema.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b576ad98-0b23-4302-96e0-cee897800d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+---------------+---------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|work_year|experience_level|employment_type|job_title|salary|salary_currency|salary_in_usd|employee_residence|remote_ratio|company_location|company_size|\n",
      "+---------+----------------+---------------+---------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|0        |2020            |MI             |FT       |NULL  |70000          |NULL         |79833             |NULL        |0               |DE          |\n",
      "|1        |2020            |SE             |FT       |NULL  |260000         |NULL         |260000            |NULL        |0               |JP          |\n",
      "|2        |2020            |SE             |FT       |NULL  |85000          |NULL         |109024            |NULL        |50              |GB          |\n",
      "+---------+----------------+---------------+---------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 9. continue with one dataframe, print data in dataframe using df.show\n",
    "df = df_schema\n",
    "df.show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fa9e671-431a-4488-8f35-23eff1e55d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79833</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>260000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>260000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2020</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>HN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2020</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2020</td>\n",
       "      <td>EN</td>\n",
       "      <td>FT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2020</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35735</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>HU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2020</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2020</td>\n",
       "      <td>SE</td>\n",
       "      <td>FT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "      <td>NZ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_year experience_level employment_type job_title  salary  \\\n",
       "0          0             2020              MI        FT     NaN   \n",
       "1          1             2020              SE        FT     NaN   \n",
       "2          2             2020              SE        FT     NaN   \n",
       "3          3             2020              MI        FT     NaN   \n",
       "4          4             2020              SE        FT     NaN   \n",
       "5          5             2020              EN        FT     NaN   \n",
       "6          6             2020              SE        FT     NaN   \n",
       "7          7             2020              MI        FT     NaN   \n",
       "8          8             2020              MI        FT     NaN   \n",
       "9          9             2020              SE        FT     NaN   \n",
       "\n",
       "  salary_currency  salary_in_usd employee_residence  remote_ratio  \\\n",
       "0           70000            NaN              79833           NaN   \n",
       "1          260000            NaN             260000           NaN   \n",
       "2           85000            NaN             109024           NaN   \n",
       "3           20000            NaN              20000           NaN   \n",
       "4          150000            NaN             150000           NaN   \n",
       "5           72000            NaN              72000           NaN   \n",
       "6          190000            NaN             190000           NaN   \n",
       "7        11000000            NaN              35735           NaN   \n",
       "8          135000            NaN             135000           NaN   \n",
       "9          125000            NaN             125000           NaN   \n",
       "\n",
       "  company_location company_size  \n",
       "0                0           DE  \n",
       "1                0           JP  \n",
       "2               50           GB  \n",
       "3                0           HN  \n",
       "4               50           US  \n",
       "5              100           US  \n",
       "6              100           US  \n",
       "7               50           HU  \n",
       "8              100           US  \n",
       "9               50           NZ  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   work_year experience_level employment_type job_title  salary  \\\n",
      "0          0             2020              MI        FT     NaN   \n",
      "1          1             2020              SE        FT     NaN   \n",
      "2          2             2020              SE        FT     NaN   \n",
      "3          3             2020              MI        FT     NaN   \n",
      "4          4             2020              SE        FT     NaN   \n",
      "5          5             2020              EN        FT     NaN   \n",
      "6          6             2020              SE        FT     NaN   \n",
      "7          7             2020              MI        FT     NaN   \n",
      "8          8             2020              MI        FT     NaN   \n",
      "9          9             2020              SE        FT     NaN   \n",
      "\n",
      "  salary_currency  salary_in_usd employee_residence  remote_ratio  \\\n",
      "0           70000            NaN              79833           NaN   \n",
      "1          260000            NaN             260000           NaN   \n",
      "2           85000            NaN             109024           NaN   \n",
      "3           20000            NaN              20000           NaN   \n",
      "4          150000            NaN             150000           NaN   \n",
      "5           72000            NaN              72000           NaN   \n",
      "6          190000            NaN             190000           NaN   \n",
      "7        11000000            NaN              35735           NaN   \n",
      "8          135000            NaN             135000           NaN   \n",
      "9          125000            NaN             125000           NaN   \n",
      "\n",
      "  company_location company_size  \n",
      "0                0           DE  \n",
      "1                0           JP  \n",
      "2               50           GB  \n",
      "3                0           HN  \n",
      "4               50           US  \n",
      "5              100           US  \n",
      "6              100           US  \n",
      "7               50           HU  \n",
      "8              100           US  \n",
      "9               50           NZ  \n"
     ]
    }
   ],
   "source": [
    "# 10. print data using display(df.toPandas())\n",
    "# В Python просто df.show(); в Jupyter можно display(df.toPandas()) - красиво отображение \n",
    "display(df.toPandas().head(10))\n",
    "print(df.limit(10).toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b166a07-79c2-4776-8f21-891c0ab7a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. create df_job_title with unique job_titles - создаём фрейм с уник знач\n",
    "df_job_title = df.select(\"job_title\").distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "518074eb-ed27-4ce9-8a7d-bc2fc9b2395c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique job titles count: 4\n",
      "+---------+\n",
      "|job_title|\n",
      "+---------+\n",
      "|CT       |\n",
      "|FL       |\n",
      "|FT       |\n",
      "|PT       |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 12. print all rows from df_job_title without truncating\n",
    "job_count = df_job_title.count()\n",
    "print(f\"Unique job titles count: {job_count}\")\n",
    "df_job_title.orderBy(\"job_title\").show(job_count, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea0eb5f2-3caa-4599-8d07-269ee256c110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. create df_analytic with max, avg, min USD salaries per job_title\n",
    "df_analytic = df.groupBy(\"job_title\").agg(\n",
    "    avg(col(\"salary_in_usd\")).alias(\"avg_salary\"),\n",
    "    min(col(\"salary_in_usd\")).alias(\"min_salary\"),\n",
    "    max(col(\"salary_in_usd\")).alias(\"max_salary\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19522c53-d72c-4921-86e2-eaef58bd3441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytic rows: 4\n",
      "+---------+----------+----------+----------+\n",
      "|job_title|avg_salary|min_salary|max_salary|\n",
      "+---------+----------+----------+----------+\n",
      "|FT       |NULL      |NULL      |NULL      |\n",
      "|PT       |NULL      |NULL      |NULL      |\n",
      "|CT       |NULL      |NULL      |NULL      |\n",
      "|FL       |NULL      |NULL      |NULL      |\n",
      "+---------+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 14. print all rows from df_analytic without truncating jobs\n",
    "count_analytic = df_analytic.count()\n",
    "print(f\"Analytic rows: {count_analytic}\")\n",
    "df_analytic.orderBy(col(\"avg_salary\").desc()).show(count_analytic, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e22d983-44f5-435a-ab5a-fe75ae60df8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. add row_id ordered by avg_salary desc\n",
    "w = Window.orderBy(col(\"avg_salary\").desc())\n",
    "df_analytic = df_analytic.withColumn(\"row_id\", row_number().over(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18fad640-f25a-4ce1-a0da-c706658e45ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+----------+----------+------+\n",
      "|job_title|avg_salary|min_salary|max_salary|row_id|\n",
      "+---------+----------+----------+----------+------+\n",
      "|FT       |NULL      |NULL      |NULL      |1     |\n",
      "|PT       |NULL      |NULL      |NULL      |2     |\n",
      "|CT       |NULL      |NULL      |NULL      |3     |\n",
      "|FL       |NULL      |NULL      |NULL      |4     |\n",
      "+---------+----------+----------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 16. print all data from df_analytic\n",
    "df_analytic.orderBy(col(\"row_id\")).show(count_analytic, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cc77e09-9bb7-4680-8803-2fbe4383c184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17. put row_id on first place\n",
    "cols = df_analytic.columns\n",
    "# желаемый порядок row_id, остальное так\n",
    "new_order = [\"row_id\"] + [c for c in cols if c != \"row_id\"]\n",
    "df_analytic = df_analytic.select(*new_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc469e44-d91b-4cdb-a4c3-cfa88fb8eb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+----------+----------+----------+\n",
      "|row_id|job_title|avg_salary|min_salary|max_salary|\n",
      "+------+---------+----------+----------+----------+\n",
      "|1     |FT       |NULL      |NULL      |NULL      |\n",
      "|2     |PT       |NULL      |NULL      |NULL      |\n",
      "|3     |CT       |NULL      |NULL      |NULL      |\n",
      "|4     |FL       |NULL      |NULL      |NULL      |\n",
      "+------+---------+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 18. print df_analytic now\n",
    "df_analytic.show(count_analytic, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6dd2c262-f518-414f-a794-7cd21f0e6170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_exp_lvl (one row per experience_level with biggest salary):\n",
      "+---------+----------------+---------------+---------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|work_year|experience_level|employment_type|job_title|salary|salary_currency|salary_in_usd|employee_residence|remote_ratio|company_location|company_size|\n",
      "+---------+----------------+---------------+---------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "|0        |2020            |MI             |FT       |NULL  |70000          |NULL         |79833             |NULL        |0               |DE          |\n",
      "|72       |2021            |EN             |FT       |NULL  |60000          |NULL         |82528             |NULL        |50              |GB          |\n",
      "|289      |2022            |SE             |FT       |NULL  |135000         |NULL         |135000            |NULL        |100             |US          |\n",
      "+---------+----------------+---------------+---------+------+---------------+-------------+------------------+------------+----------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 19. create df_exp_lvl with the biggest usd_salary (biggest_salary) for each experience_level\n",
    "#    (save all fields like in entire dataframe) — т.е. для каждой exp_level взять строку с max salary_in_usd\n",
    "w_exp = Window.partitionBy(\"experience_level\").orderBy(col(\"salary_in_usd\").desc())\n",
    "df_with_row = df.withColumn(\"rn\", row_number().over(w_exp))\n",
    "df_exp_lvl = df_with_row.filter(col(\"rn\") == 1).drop(\"rn\")\n",
    "print(\"df_exp_lvl (one row per experience_level with biggest salary):\")\n",
    "df_exp_lvl.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19df60e2-32e0-4a71-8ba4-59435a7aceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20. print df_exp_lvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a5023a9-4626-4cfc-8abb-ea5526f56579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_best (potentially multiple rows per exp level if tie):\n",
      "+---+----------------+--------------+------------------+\n",
      "|id |experience_level|biggest_salary|employee_residence|\n",
      "+---+----------------+--------------+------------------+\n",
      "+---+----------------+--------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 21. create df_best: rows where salary == biggest salary for people in his exp_lvl\n",
    "#     choose only columns: id, experience_level, biggest_salary, employee_residence\n",
    "if \"id\" in df.columns:\n",
    "    id_col = \"id\"\n",
    "else:\n",
    "    # если нет id, создадим уникальный id\n",
    "    from pyspark.sql.functions import monotonically_increasing_id\n",
    "    df = df.withColumn(\"id\", monotonically_increasing_id())\n",
    "    id_col = \"id\"\n",
    "\n",
    "max_by_exp = df.groupBy(\"experience_level\").agg(max(\"salary_in_usd\").alias(\"biggest_salary\"))\n",
    "\n",
    "# Соед с исходной таблицей, чтобы взять строки, где salary_in_usd == biggest_salary и совпадает experience_level\n",
    "df_best = (df.join(max_by_exp, on=\"experience_level\", how=\"inner\")\n",
    "           .filter(col(\"salary_in_usd\") == col(\"biggest_salary\"))\n",
    "           .select(id_col, \"experience_level\", \"biggest_salary\", \"employee_residence\"))\n",
    "\n",
    "print(\"df_best (potentially multiple rows per exp level if tie):\")\n",
    "df_best.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f919db5-9276-4a99-b191-f80cd3ca4208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23. drop duplicates by experience_level \n",
    "df_best = df_best.dropDuplicates([\"experience_level\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3426b404-17a6-413e-86a3-9351368270f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_best after dropping duplicates by experience_level:\n",
      "+---+----------------+--------------+------------------+\n",
      "|id |experience_level|biggest_salary|employee_residence|\n",
      "+---+----------------+--------------+------------------+\n",
      "+---+----------------+--------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 24. print df_best\n",
    "print(\"df_best after dropping duplicates by experience_level:\")\n",
    "df_best.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e139094-e734-4bf5-a53c-ac45707ab05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25. create df_new_best from df_best without id, map MI->middle, SE->senior, else Null\n",
    "df_new_best = df_best.drop(id_col).withColumn(\n",
    "    \"experience_level\",\n",
    "    when(col(\"experience_level\") == \"MI\", \"middle\")\n",
    "    .when(col(\"experience_level\") == \"SE\", \"senior\")\n",
    "    .otherwise(None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2a16678-1457-4d90-a162-49742c845849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_new_best:\n",
      "+----------------+--------------+------------------+\n",
      "|experience_level|biggest_salary|employee_residence|\n",
      "+----------------+--------------+------------------+\n",
      "+----------------+--------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 26. print df_new_best\n",
    "print(\"df_new_best:\")\n",
    "df_new_best.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9ecb273c-446d-4f37-8efa-7727e6bade94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 27. write df_new_best like 1.csv and load then it to df_final\n",
    "out_path = \"/tmp/df_new_best_1.csv\"  # путь можно поменять\n",
    "(df_new_best.coalesce(1)\n",
    " .write\n",
    " .option(\"header\", True)\n",
    " .mode(\"overwrite\")\n",
    " .csv(out_path))\n",
    "\n",
    "df_final = (spark.read\n",
    "            .option(\"header\", True)\n",
    "            .csv(out_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6131dd9a-8890-4963-95a2-c7fc91311824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_final (read from CSV):\n",
      "+----------------+--------------+------------------+\n",
      "|experience_level|biggest_salary|employee_residence|\n",
      "+----------------+--------------+------------------+\n",
      "+----------------+--------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 28. print df_final\n",
    "print(\"df_final (read from CSV):\")\n",
    "df_final.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9934bdce-ee5f-4a89-8ea1-0094d6cb2a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 29. filter df_final to delete experience_level where it Null, then join by biggest_salary and employee_residence with entire df\n",
    "df_final_filtered = df_final.filter(col(\"experience_level\").isNotNull())\n",
    "\n",
    "df_final_filtered = df_final_filtered.withColumn(\"biggest_salary\", col(\"biggest_salary\").cast(\"double\"))\n",
    "df_joined = (df_final_filtered.join(df,\n",
    "                                   (df_final_filtered.biggest_salary == df.salary_in_usd) &\n",
    "                                   (df_final_filtered.employee_residence == df.employee_residence),\n",
    "                                   how=\"inner\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d29537f-656a-4a43-b644-08fc60cfbd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_joined (result of join):\n",
      "+----------------+--------------+------------------+---------+----------------+---------------+---------+------+---------------+-------------+------------------+------------+----------------+------------+---+\n",
      "|experience_level|biggest_salary|employee_residence|work_year|experience_level|employment_type|job_title|salary|salary_currency|salary_in_usd|employee_residence|remote_ratio|company_location|company_size|id |\n",
      "+----------------+--------------+------------------+---------+----------------+---------------+---------+------+---------------+-------------+------------------+------------+----------------+------------+---+\n",
      "+----------------+--------------+------------------+---------+----------------+---------------+---------+------+---------------+-------------+------------------+------------+----------------+------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 30. print df_final\n",
    "print(\"df_joined (result of join):\")\n",
    "df_joined.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15ebd010-59b3-42f5-805a-82f07e8ce974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max salary_in_usd from df_final (joined): None\n"
     ]
    }
   ],
   "source": [
    "# 31. save biggest salary_in_usd from df_final to variable and print it\n",
    "from pyspark.sql.functions import max as spark_max_fn\n",
    "max_salary_row = df_joined.agg(spark_max_fn(\"salary_in_usd\").alias(\"max_salary\")).collect()[0]\n",
    "max_salary_value = max_salary_row[\"max_salary\"]\n",
    "print(\"Max salary_in_usd from df_final (joined):\", max_salary_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
